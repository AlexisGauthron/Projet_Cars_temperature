# -*- coding: utf-8 -*-
"""
Script de t√©l√©chargement du dataset SVIRO (100 images par v√©hicule).
SVIRO: Synthetic Vehicle Interior Rear Seat Occupancy Dataset
https://sviro.kl.dfki.de/
"""

import os
import sys
import random
import zipfile
import requests
from pathlib import Path
from typing import Optional
import shutil

# Configuration
SVIRO_DIR = Path(__file__).parent.parent / "datasets" / "sviro"
IMAGES_PER_VEHICLE = 100

# URLs des archives (grayscale - plus l√©g√®res que RGB)
GRAYSCALE_URLS = {
    "bmw_i3": "https://sviro.kl.dfki.de/download/i3/?wpdmdl=378",
    "bmw_x5": "https://sviro.kl.dfki.de/download/bmw-x5/?wpdmdl=387",
    "ford_escape": "https://sviro.kl.dfki.de/download/escape/?wpdmdl=376",
    "hyundai_tucson": "https://sviro.kl.dfki.de/download/hyundai-tucson/?wpdmdl=380",
    "lexus_gsf": "https://sviro.kl.dfki.de/download/lexus/?wpdmdl=379",
    "mercedes_a": "https://sviro.kl.dfki.de/download/grayscale-tesla/?wpdmdl=368",
    "renault_zoe": "https://sviro.kl.dfki.de/download/renault-zoe/?wpdmdl=382",
    "tesla_model3": "https://sviro.kl.dfki.de/download/tesla-model-3/?wpdmdl=383",
    "toyota_hilux": "https://sviro.kl.dfki.de/download/hilux/?wpdmdl=377",
    "vw_tiguan": "https://sviro.kl.dfki.de/download/vw-tiguan/?wpdmdl=384",
}

# URLs des bounding boxes
BBOX_URLS = {
    "bmw_i3": "https://sviro.kl.dfki.de/download/bmw-i3-5/?wpdmdl=456",
    "bmw_x5": "https://sviro.kl.dfki.de/download/bmw-x5-6/?wpdmdl=457",
    "ford_escape": "https://sviro.kl.dfki.de/download/ford-escape-5/?wpdmdl=459",
    "hyundai_tucson": "https://sviro.kl.dfki.de/download/hyundai-tucson-6/?wpdmdl=460",
    "lexus_gsf": "https://sviro.kl.dfki.de/download/lexus-gs-f-5/?wpdmdl=461",
    "mercedes_a": "https://sviro.kl.dfki.de/download/mercedes-class-a-5/?wpdmdl=462",
    "renault_zoe": "https://sviro.kl.dfki.de/download/renault-zoe-6/?wpdmdl=463",
    "tesla_model3": "https://sviro.kl.dfki.de/download/tesla-model-3-6/?wpdmdl=464",
    "toyota_hilux": "https://sviro.kl.dfki.de/download/toyota-hilux-5/?wpdmdl=465",
    "vw_tiguan": "https://sviro.kl.dfki.de/download/vw-tiguan-6/?wpdmdl=466",
}


def download_file(url: str, dest: Path, desc: str = "") -> bool:
    """T√©l√©charge un fichier avec barre de progression."""
    try:
        print(f"  T√©l√©chargement: {desc or url}")

        response = requests.get(url, stream=True, allow_redirects=True)
        response.raise_for_status()

        # Taille totale
        total_size = int(response.headers.get('content-length', 0))

        dest.parent.mkdir(parents=True, exist_ok=True)

        downloaded = 0
        with open(dest, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    if total_size > 0:
                        pct = downloaded / total_size * 100
                        print(f"\r  Progression: {pct:.1f}% ({downloaded / 1024 / 1024:.1f} MB)", end="")

        print()
        return True

    except Exception as e:
        print(f"\n  ‚ùå Erreur: {e}")
        return False


def extract_random_images(zip_path: Path, dest_dir: Path, num_images: int, vehicle: str) -> list:
    """Extrait N images al√©atoires d'une archive ZIP."""
    extracted = []

    try:
        with zipfile.ZipFile(zip_path, 'r') as zf:
            # Lister toutes les images PNG/JPG dans l'archive
            all_images = [
                f for f in zf.namelist()
                if f.lower().endswith(('.png', '.jpg', '.jpeg'))
                and not f.startswith('__MACOSX')
            ]

            if not all_images:
                print(f"  ‚ö†Ô∏è  Aucune image trouv√©e dans l'archive")
                return []

            # S√©lectionner N images al√©atoires
            selected = random.sample(all_images, min(num_images, len(all_images)))

            print(f"  Extraction de {len(selected)} images...")

            for img_path in selected:
                # Nom simplifi√©: vehicle_originalname.png
                original_name = Path(img_path).name
                new_name = f"{vehicle}_{original_name}"
                dest_path = dest_dir / new_name

                # Extraire l'image
                with zf.open(img_path) as src, open(dest_path, 'wb') as dst:
                    dst.write(src.read())

                extracted.append(new_name)

            print(f"  ‚úÖ {len(extracted)} images extraites")

    except Exception as e:
        print(f"  ‚ùå Erreur extraction: {e}")

    return extracted


def download_bbox_annotations(vehicle: str, dest_dir: Path) -> Optional[Path]:
    """T√©l√©charge et extrait les annotations bounding box."""
    url = BBOX_URLS.get(vehicle)
    if not url:
        return None

    zip_path = dest_dir / f"{vehicle}_bbox.zip"

    if not download_file(url, zip_path, f"Bounding boxes {vehicle}"):
        return None

    # Extraire
    try:
        with zipfile.ZipFile(zip_path, 'r') as zf:
            # Trouver les fichiers CSV/TXT d'annotations
            for f in zf.namelist():
                if f.endswith('.csv') or f.endswith('.txt') or f.endswith('.json'):
                    zf.extract(f, dest_dir / "annotations" / vehicle)

        zip_path.unlink()  # Supprimer le ZIP
        return dest_dir / "annotations" / vehicle

    except Exception as e:
        print(f"  ‚ùå Erreur extraction annotations: {e}")
        return None


def download_vehicle(vehicle: str, images_dir: Path, temp_dir: Path) -> list:
    """T√©l√©charge les images d'un v√©hicule."""
    url = GRAYSCALE_URLS.get(vehicle)
    if not url:
        print(f"  ‚ö†Ô∏è  URL non trouv√©e pour {vehicle}")
        return []

    zip_path = temp_dir / f"{vehicle}.zip"

    # T√©l√©charger l'archive
    if not download_file(url, zip_path, f"Images {vehicle}"):
        return []

    # Extraire les images al√©atoires
    extracted = extract_random_images(zip_path, images_dir, IMAGES_PER_VEHICLE, vehicle)

    # Supprimer l'archive pour √©conomiser de l'espace
    if zip_path.exists():
        zip_path.unlink()
        print(f"  üóëÔ∏è  Archive supprim√©e")

    return extracted


def main():
    """Point d'entr√©e principal."""
    print("=" * 60)
    print("SVIRO Dataset Downloader")
    print(f"T√©l√©chargement de {IMAGES_PER_VEHICLE} images par v√©hicule")
    print("=" * 60)

    # Cr√©er les dossiers
    images_dir = SVIRO_DIR / "images"
    annotations_dir = SVIRO_DIR / "annotations"
    temp_dir = SVIRO_DIR / "temp"

    images_dir.mkdir(parents=True, exist_ok=True)
    annotations_dir.mkdir(parents=True, exist_ok=True)
    temp_dir.mkdir(parents=True, exist_ok=True)

    all_images = {}
    vehicles = list(GRAYSCALE_URLS.keys())

    print(f"\nüì¶ {len(vehicles)} v√©hicules √† t√©l√©charger\n")

    for i, vehicle in enumerate(vehicles, 1):
        print(f"\n[{i}/{len(vehicles)}] {vehicle.upper()}")
        print("-" * 40)

        # T√©l√©charger les images
        images = download_vehicle(vehicle, images_dir, temp_dir)
        all_images[vehicle] = images

        # T√©l√©charger les annotations
        download_bbox_annotations(vehicle, SVIRO_DIR)

    # Nettoyer le dossier temp
    if temp_dir.exists():
        shutil.rmtree(temp_dir)

    # Cr√©er un fichier d'index
    index_file = SVIRO_DIR / "index.txt"
    with open(index_file, 'w') as f:
        for vehicle, images in all_images.items():
            for img in images:
                f.write(f"{img}\n")

    # R√©sum√©
    print("\n" + "=" * 60)
    print("‚úÖ T√âL√âCHARGEMENT TERMIN√â")
    print("=" * 60)

    total_images = sum(len(imgs) for imgs in all_images.values())
    print(f"\nüìä R√©sum√©:")
    print(f"   - Images totales: {total_images}")
    print(f"   - V√©hicules: {len(vehicles)}")
    print(f"   - Dossier: {SVIRO_DIR}")

    for vehicle, images in all_images.items():
        status = "‚úÖ" if len(images) >= IMAGES_PER_VEHICLE else f"‚ö†Ô∏è ({len(images)})"
        print(f"   - {vehicle}: {status}")


if __name__ == "__main__":
    main()
